{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RGEogWlpLNDO"},"outputs":[],"source":["# Install core dependencies\n","!pip install torch torchvision torchaudio torch-geometric numpy==1.23.5 pandas scikit-learn tqdm\n","!pip install rdkit-pypi deepchem networkx matplotlib\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2276,"status":"ok","timestamp":1742880072417,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"qpVFSdXyQp5C","outputId":"a44e4816-d48b-412e-964f-44500720f572"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-03-25 05:21:09--  https://github.com/aspuru-guzik-group/chemical_vae/raw/main/models/zinc/250k_rndm_zinc_drugs_clean_3.csv\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/main/models/zinc/250k_rndm_zinc_drugs_clean_3.csv [following]\n","--2025-03-25 05:21:09--  https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/main/models/zinc/250k_rndm_zinc_drugs_clean_3.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 22606589 (22M) [text/plain]\n","Saving to: ‘250k_rndm_zinc_drugs_clean_3.csv’\n","\n","250k_rndm_zinc_drug 100%[===================\u003e]  21.56M  --.-KB/s    in 0.1s    \n","\n","2025-03-25 05:21:11 (153 MB/s) - ‘250k_rndm_zinc_drugs_clean_3.csv’ saved [22606589/22606589]\n","\n"]}],"source":["!wget https://github.com/aspuru-guzik-group/chemical_vae/raw/main/models/zinc/250k_rndm_zinc_drugs_clean_3.csv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzfyTfD-RDyo"},"outputs":[],"source":["pip install datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":12616,"status":"ok","timestamp":1742880120272,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"2uZrNQz5RKlx","outputId":"355236a6-bd68-4636-e80b-4467be721969"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06c7c31657fc469b8ad90194c2698ca0","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/802 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7729d9fd7cb3462c98c27f555bc0b22f","version_major":2,"version_minor":0},"text/plain":["zinc250k_selfies.csv:   0%|          | 0.00/69.3M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3379b551d97481aa8f53a7f53b1cbce","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/249455 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"edmanft/zinc250k\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1742880258368,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"62hceXkqRVST","outputId":"3f93e5e8-71e2-4471-9ea0-a708fffaad4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              smiles     logP       qed  \\\n","0          CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1\\n  5.05060  0.702012   \n","1     C[C@@H]1CC(Nc2cncc(-c3nncn3C)c2)C[C@@H](C)C1\\n  3.11370  0.928975   \n","2  N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)...  4.96778  0.599682   \n","3  CCOC(=O)[C@@H]1CCCN(C(=O)c2nc(-c3ccc(C)cc3)n3c...  4.00022  0.690944   \n","4  N#CC1=C(SCC(=O)Nc2cccc(Cl)c2)N=C([O-])[C@H](C#...  3.60956  0.789027   \n","\n","        SAS  \n","0  2.084095  \n","1  3.432004  \n","2  2.470633  \n","3  2.822753  \n","4  4.035182  \n"]}],"source":["import pandas as pd\n","\n","# Replace 'path_to_dataset' with the actual path to the downloaded CSV file\n","file_path = '/content/250k_rndm_zinc_drugs_clean_3.csv'\n","\n","# Load the dataset\n","df = pd.read_csv(file_path)\n","\n","# Display the first few rows of the dataframe\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNTfeiFlRyFI"},"outputs":[],"source":["df = pd.read_csv(file_path, on_bad_lines='skip')  # ✅ Works in Pandas 1.3+\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AA-xC4wAobWt"},"outputs":[],"source":["!pip install rdkit\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":679600,"status":"ok","timestamp":1742888711133,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"4XnlbMbpSCR2","outputId":"a134d338-b3a3-441d-a3ac-af2adb05aa0e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 249455/249455 [11:15\u003c00:00, 369.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Successfully converted 249455 molecules into graphs!\n"]}],"source":["import torch\n","from rdkit import Chem\n","from torch_geometric.utils import from_networkx\n","import networkx as nx\n","from tqdm import tqdm\n","\n","# Function to convert a SMILES string into a graph\n","def smiles_to_graph(smiles):\n","    try:\n","        mol = Chem.MolFromSmiles(smiles)\n","        if mol is None:\n","            return None\n","\n","        G = nx.Graph()\n","        node_features = []\n","\n","        for atom in mol.GetAtoms():\n","            G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n","            node_features.append([atom.GetAtomicNum()])\n","\n","        for bond in mol.GetBonds():\n","            G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n","\n","        graph = from_networkx(G)\n","        graph.x = torch.tensor(node_features, dtype=torch.float32)\n","        return graph\n","    except Exception:\n","        return None\n","\n","# Apply conversion (Show progress bar)\n","df[\"Graph\"] = [smiles_to_graph(sm) for sm in tqdm(df[\"smiles\"])]\n","\n","# Remove invalid graphs\n","df = df.dropna(subset=[\"Graph\"]).reset_index(drop=True)\n","\n","print(f\"Successfully converted {len(df)} molecules into graphs!\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":817,"status":"ok","timestamp":1742888724277,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"-V8CZEglUcTL"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch_geometric.nn import GCNConv\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GNNModel, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index).relu()\n","        x = self.fc(x)\n","        return torch.sigmoid(x)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385839,"status":"ok","timestamp":1742889113360,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"inXrVqPeV4dw","outputId":"e56faac8-ebf5-4443-a78b-f323ef69bc64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Loss: 0.0017447273831561303\n","Epoch 2/5, Loss: 6.124101327850679e-10\n","Epoch 3/5, Loss: 5.93958193158722e-12\n","Epoch 4/5, Loss: 3.6938690804030317e-13\n","Epoch 5/5, Loss: 2.5032496420909366e-13\n","Training complete!\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch_geometric.loader import DataLoader\n","\n","# Move model to GPU (if available)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Determine input dimension dynamically\n","input_dim = df[\"Graph\"][0].x.shape[1]  # Get correct feature size\n","\n","# Define the GNN model\n","model = GNNModel(input_dim=input_dim, hidden_dim=64, output_dim=1).to(device)\n","\n","# Define optimizer and loss function\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = nn.BCELoss()\n","\n","# Convert dataset into PyTorch DataLoader for batching\n","batch_size = 32\n","train_loader = DataLoader(df[\"Graph\"].tolist(), batch_size=batch_size, shuffle=True)\n","\n","# Training loop\n","epochs = 5\n","for epoch in range(epochs):\n","    total_loss = 0.0\n","    model.train()  # Set model to training mode\n","\n","    for batch in train_loader:\n","        batch = batch.to(device)  # Move batch to GPU\n","        optimizer.zero_grad()\n","\n","        pred = model(batch.x, batch.edge_index)  # Forward pass\n","        target = torch.ones(batch.x.size(0), device=device)  # Example target (adjust as needed)\n","\n","        loss = loss_fn(pred.view(-1), target.view(-1))  # Ensure shape matches\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n","\n","print(\"Training complete!\")\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1742889154710,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"4v86laTau_Dv","outputId":"3c940a4e-1e5c-4198-bfcc-0371e707141b"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model saved successfully!\n","✅ Test Prediction: 1.0\n"]}],"source":["import torch\n","\n","# Save the trained model\n","torch.save(model.state_dict(), \"gnn_model.pth\")\n","print(\"✅ Model saved successfully!\")\n","\n","# Load the model for inference\n","model.load_state_dict(torch.load(\"gnn_model.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","model.eval()\n","\n","# Ensure dataset is loaded before inference\n","if \"Graph\" not in df.columns or len(df) == 0:\n","    raise ValueError(\"❌ Error: Dataset does not contain the 'Graph' column or is empty!\")\n","\n","# Select a sample molecule\n","sample_graph = df[\"Graph\"].iloc[0]  # Get first molecule graph\n","\n","# Ensure `x` and `edge_index` exist before passing to model\n","if not hasattr(sample_graph, 'x') or not hasattr(sample_graph, 'edge_index'):\n","    raise ValueError(\"❌ Error: Sample graph does not contain 'x' (features) or 'edge_index' (connections)!\")\n","\n","# Move tensors to the correct device (CPU/GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","x, edge_index = sample_graph.x.to(device), sample_graph.edge_index.to(device)\n","\n","# Run inference in evaluation mode\n","with torch.no_grad():\n","    pred = model(x, edge_index)\n","\n","    # Fix: Convert tensor to scalar (if multiple values exist)\n","    if pred.numel() \u003e 1:\n","        pred_value = pred.mean().item()  # Compute mean if multiple values exist\n","    else:\n","        pred_value = pred.item()  # Convert single tensor to scalar\n","\n","    print(\"✅ Test Prediction:\", pred_value)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1742889160485,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"cWLEosiuYHOI","outputId":"6b38ebb8-6d6c-4802-c4ed-d00f434cad4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model saved successfully!\n","✅ Model loaded for inference!\n"]}],"source":["# Save model\n","torch.save(model.state_dict(), \"gnn_model.pth\")\n","print(\"✅ Model saved successfully!\")\n","\n","# Reload model when needed\n","model.load_state_dict(torch.load(\"gnn_model.pth\"))\n","model.eval()\n","print(\"✅ Model loaded for inference!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QvC1Dz_RYjv-"},"outputs":[],"source":["!pip install fastapi uvicorn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89,"status":"ok","timestamp":1742823443334,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"qlFU1WVUYr3z","outputId":"956bf5d9-df94-4f05-c2d8-6b9640877083"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ FastAPI installed successfully!\n"]}],"source":["import fastapi\n","print(\"✅ FastAPI installed successfully!\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1405,"status":"ok","timestamp":1742889183103,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"ClpYrvwCYu8r"},"outputs":[],"source":["from fastapi import FastAPI\n","import uvicorn\n","import threading\n","\n","app = FastAPI()\n","\n","@app.get(\"/\")\n","def read_root():\n","    return {\"message\": \"🚀 FastAPI is running in Google Colab!\"}\n","\n","# Function to start the server\n","def run():\n","    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","\n","# Run FastAPI in a separate thread\n","thread = threading.Thread(target=run)\n","thread.start()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khDEE2F1ZRUh"},"outputs":[],"source":["!pip install pyngrok fastapi uvicorn\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1742889206805,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"8vhUstbfw7tr"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GNNModel, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n","        self.fc = nn.Linear(hidden_dim, output_dim)  # Matches saved model\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = self.fc(x)\n","        return torch.sigmoid(x)  # Ensure output is a probability\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1742889209663,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"2Ab4GetfxAIZ","outputId":"e2c3f587-aa3e-4feb-b8e7-c98d28f2b107"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model loaded successfully!\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the model with the same structure as during training\n","model = GNNModel(input_dim=1, hidden_dim=64, output_dim=1).to(device)\n","\n","# Load state_dict with strict=False to ignore mismatches\n","checkpoint = torch.load(\"gnn_model.pth\", map_location=device)\n","model.load_state_dict(checkpoint, strict=False)\n","\n","# Set model to evaluation mode\n","model.eval()\n","print(\"✅ Model loaded successfully!\")\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1742889212095,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"77MDsnOXxEYK","outputId":"8f0151a7-f60c-4f95-aa08-87c2a2021e61"},"outputs":[{"name":"stdout","output_type":"stream","text":["conv1.bias: torch.Size([64])\n","conv1.lin.weight: torch.Size([64, 1])\n","conv2.bias: torch.Size([64])\n","conv2.lin.weight: torch.Size([64, 64])\n","fc.weight: torch.Size([1, 64])\n","fc.bias: torch.Size([1])\n"]}],"source":["for name, param in model.named_parameters():\n","    print(f\"{name}: {param.shape}\")\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1742889214762,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"yk9t3jxPxKXn","outputId":"195ec26a-5c2a-4fb1-a3be-19afcfa2c93d"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model re-saved successfully!\n"]}],"source":["torch.save(model.state_dict(), \"gnn_model_fixed.pth\")\n","print(\"✅ Model re-saved successfully!\")\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1742889218254,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"OZhRo8r4xOC6","outputId":"1bdddc36-6a30-45c8-8524-9220050d51b7"},"outputs":[{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"gnn_model_fixed.pth\", map_location=device))\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1742889221718,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"bU-r06UzxQ9p","outputId":"ba473557-0be0-4847-cc9b-8fb9a574b7a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔬 Test Prediction: 1.0\n"]}],"source":["with torch.no_grad():\n","    sample_graph = df[\"Graph\"][0]\n","    x, edge_index = sample_graph.x.to(device), sample_graph.edge_index.to(device)\n","\n","    pred = model(x, edge_index)\n","    print(\"🔬 Test Prediction:\", pred.mean().item())  # Compute mean if multiple values exist\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1742889227749,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"wR7ZCRn4yx4x","outputId":"1e5ee4e6-cc39-4c92-b26c-fd2a4d09841c"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔍 Model State Dict Keys: odict_keys(['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'fc.weight', 'fc.bias'])\n"]}],"source":["import torch\n","\n","# Load model weights to check the architecture\n","state_dict = torch.load(\"gnn_model.pth\", map_location=\"cpu\")\n","print(\"🔍 Model State Dict Keys:\", state_dict.keys())\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1742889230874,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"c2BEOHZZy8Yg","outputId":"665397de-aae5-4175-924b-ef2aeda51713"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model loaded successfully!\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch_geometric.nn as pyg_nn\n","\n","class GNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GNNModel, self).__init__()\n","        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim)\n","        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index).relu()\n","        x = self.fc(x)\n","        return torch.sigmoid(x)\n","\n","# Load model with matching architecture\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = GNNModel(input_dim=1, hidden_dim=64, output_dim=1).to(device)\n","\n","# Load trained weights\n","model.load_state_dict(torch.load(\"gnn_model.pth\", map_location=device))\n","model.eval()\n","\n","print(\"✅ Model loaded successfully!\")\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1742889235244,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"95HQ7Zgd0FHE","outputId":"52af0b6c-6e7c-49a4-ebc6-a1a19aeae25f"},"outputs":[{"data":{"text/plain":["GNNModel(\n","  (conv1): GCNConv(1, 64)\n","  (conv2): GCNConv(64, 64)\n","  (fc): Linear(in_features=64, out_features=1, bias=True)\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","# Define the correct model architecture\n","class GNNModel(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(GNNModel, self).__init__()\n","        self.conv1 = GCNConv(input_dim, hidden_dim)  # Graph Convolution Layer\n","        self.conv2 = GCNConv(hidden_dim, hidden_dim)  # Second GCN Layer\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)  # Fully Connected Layer\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = self.fc(x)\n","        return torch.sigmoid(x)  # Ensure output is between 0-1 for binary classification\n","\n","# Load Model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = GNNModel(input_dim=1, hidden_dim=64, output_dim=1).to(device)\n","\n","# Load the correct state_dict\n","model.load_state_dict(torch.load(\"gnn_model.pth\", map_location=device))\n","model.eval()\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1742889240450,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"sSNnSQg50IhL","outputId":"00d4eeed-432a-4f7a-87f9-a80024f70a92"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔬 Test Prediction: 1.0000\n"]}],"source":["with torch.no_grad():\n","    pred = model(x, edge_index).mean().item()  # Compute mean prediction\n","    print(f\"🔬 Test Prediction: {pred:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"xZOewzvj0t-Z"},"source":["This the sample of testing the drug using the drugs smile formats eg:Paracetamol (SMILES: CC(=O)NC1=CC=C(C=C1)O)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1742889244356,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"ZxNo2S0I0NjA","outputId":"4ab2cb0b-2d3e-4351-d006-2548ec449ecd"},"outputs":[{"name":"stdout","output_type":"stream","text":["🔬 Prediction for CC(=O)NC1=CC=C(C=C1)O: 1.0000\n"]}],"source":["import torch\n","from rdkit import Chem\n","import networkx as nx\n","from torch_geometric.utils import from_networkx\n","\n","# Load model if not already defined\n","try:\n","    model\n","except NameError:\n","    print(\"⚠ Model not loaded! Loading now...\")\n","    model = GNNModel(input_dim=1, hidden_dim=64, output_dim=1)\n","    model.load_state_dict(torch.load(\"gnn_model.pth\", map_location=\"cpu\"))\n","    model.eval()\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Function to convert SMILES to graph format\n","def smiles_to_graph(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None:\n","        return None  # Handle invalid SMILES\n","\n","    G = nx.Graph()\n","    for atom in mol.GetAtoms():\n","        G.add_node(atom.GetIdx(), atomic_num=atom.GetAtomicNum())\n","\n","    for bond in mol.GetBonds():\n","        G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n","\n","    try:\n","        graph = from_networkx(G)\n","        graph.x = torch.tensor([[atom[\"atomic_num\"]] for _, atom in G.nodes(data=True)], dtype=torch.float32)\n","        return graph\n","    except Exception as e:\n","        print(f\"⚠ Error converting molecule to graph: {e}\")\n","        return None\n","\n","# Example molecule: Paracetamol (SMILES: CC(=O)NC1=CC=C(C=C1)O)\n","sample_smiles = \"CC(=O)NC1=CC=C(C=C1)O\"\n","sample_graph = smiles_to_graph(sample_smiles)\n","\n","if sample_graph is not None:\n","    x, edge_index = sample_graph.x.to(device), sample_graph.edge_index.to(device)\n","\n","    with torch.no_grad():\n","        try:\n","            prediction = model(x, edge_index).mean().item()  # Get prediction\n","            print(f\"🔬 Prediction for {sample_smiles}: {prediction:.4f}\")\n","        except Exception as e:\n","            print(f\"⚠ Error during model inference: {e}\")\n","else:\n","    print(\"❌ Invalid molecule!\")\n"]},{"cell_type":"markdown","metadata":{"id":"Mj1Nb6SGY8zQ"},"source":["NOW,Adding the quantum computiog its main layers Variational Quantum Circuits (VQC) to predict drug interactions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ro1T7Z3LYyO1"},"outputs":[],"source":["!pip install pennylane pennylane-qiskit torch torchvision torchaudio\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-0G0ac-afZU"},"outputs":[],"source":["!pip install --upgrade numpy jax jaxlib pennylane\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":13897,"status":"ok","timestamp":1742889800322,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"vCdM_w3nU47x","outputId":"c02c2eb5-4890-44a0-f685-52aa523f19d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: jax 0.5.3\n","Uninstalling jax-0.5.3:\n","  Successfully uninstalled jax-0.5.3\n","Found existing installation: jaxlib 0.5.3\n","Uninstalling jaxlib-0.5.3:\n","  Successfully uninstalled jaxlib-0.5.3\n","Collecting jax\n","  Using cached jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib\n","  Using cached jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: ml_dtypes\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax) (0.4.1)\n","Requirement already satisfied: numpy\u003e=1.25 in /usr/local/lib/python3.11/dist-packages (from jax) (2.0.2)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax) (3.4.0)\n","Requirement already satisfied: scipy\u003e=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax) (1.14.1)\n","Using cached jax-0.5.3-py3-none-any.whl (2.4 MB)\n","Using cached jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl (105.1 MB)\n","Installing collected packages: jaxlib, jax\n","Successfully installed jax-0.5.3 jaxlib-0.5.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"ff33dcfad4d14d6a8e45b8f6f37a4808","pip_warning":{"packages":["jaxlib"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip uninstall -y jax jaxlib\n","!pip install --upgrade jax jaxlib\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9285,"status":"ok","timestamp":1742889827218,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"LvbnqK0daC7a","outputId":"b533e880-69ce-40e5-a9c9-e39a85cba6da"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.5.1 is installed, but it is not compatible with the installed jaxlib version 0.5.3, so it will not be used.\n","  warnings.warn(\n"]}],"source":["import pennylane as qml\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from pennylane import numpy as np\n","\n","# Quantum Circuit Layer (4 Qubits, Variational Quantum Circuit)\n","n_qubits = 4  # Number of quantum bits\n","dev = qml.device(\"default.qubit\", wires=n_qubits)  # Simulating a quantum processor\n","\n","@qml.qnode(dev, interface=\"torch\")\n","def quantum_layer(inputs, weights):\n","    \"\"\"Quantum Layer with Parameterized Rotation Gates\"\"\"\n","    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))  # Encode classical data\n","    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum operation\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]  # Measurement\n","\n","# Define the updated GNN model with Quantum Layer\n","class QuantumGNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(QuantumGNNModel, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)  # Classical layer\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)  # Output layer\n","\n","        # Quantum Parameters (Trainable)\n","        weight_shapes = {\"weights\": (5, n_qubits, 3)}  # 5 layers, 4 qubits, 3 parameters each\n","        self.quantum_weights = torch.nn.Parameter(0.01 * torch.randn(weight_shapes[\"weights\"]))\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Classical processing\n","        quantum_out = torch.tensor(quantum_layer(x, self.quantum_weights), dtype=torch.float32)  # Quantum layer\n","        x = torch.cat((x, quantum_out), dim=-1)  # Merge classical and quantum output\n","        x = self.fc2(x)  # Final output\n","        return torch.sigmoid(x)  # Probability output\n","\n","# Initialize the updated model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = QuantumGNNModel(input_dim=1, hidden_dim=64, output_dim=1).to(device)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1742889922266,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"OKxx2CkFVV0q","outputId":"359f6a64-a9de-4b4c-a396-3292222adcb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['F', 'In', 'Out', 'QuantumGNNModel', '_', '__', '___', '__builtin__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', '_dh', '_i', '_i1', '_i2', '_i3', '_ih', '_ii', '_iii', '_oh', 'dev', 'device', 'exit', 'get_ipython', 'model', 'n_qubits', 'nn', 'np', 'qml', 'quantum_layer', 'quit', 'torch']\n"]}],"source":["\n","print(dir())  # Lists all defined variables\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113,"status":"ok","timestamp":1742889946537,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"UJEXDDMOVgCz","outputId":"7bd38043-158b-4be4-e247-3b92e734840f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of x_train: torch.Size([100, 32])\n"]}],"source":["# Example: If x_train is part of a dataset, reload it\n","import torch\n","\n","# Example dataset (Replace with actual data loading method)\n","x_train = torch.randn(100, 32)  # 100 samples, 32 features\n","y_train = torch.randint(0, 2, (100, 1))  # Binary labels\n","\n","print(\"Shape of x_train:\", x_train.shape)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1742889952075,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"RvyK3K3kcfL9","outputId":"01c999f7-2a44-4576-c49c-c7232cebe021"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of x_train: torch.Size([100, 32])\n"]}],"source":["print(\"Shape of x_train:\", x_train.shape)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1856,"status":"ok","timestamp":1742890997782,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"0yNoAZmiZfy_"},"outputs":[],"source":["from sklearn.decomposition import PCA\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":66,"status":"ok","timestamp":1742891015997,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"5yAzoDkpcjAo"},"outputs":[],"source":["pca = PCA(n_components=min(1, x_train.shape[1]))  # Auto-adjust to available features\n","x_train_reduced = pca.fit_transform(x_train)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1742891079647,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"x1iqD4VHuB0e","outputId":"5a413a65-6c0f-4db3-9737-8bd7dafc6b8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["New shape of x_train after PCA: torch.Size([100, 6])\n"]}],"source":["import torch\n","import numpy as np\n","from sklearn.decomposition import PCA\n","\n","# Ensure x_train has enough features (expand to at least 6 features)\n","if x_train.shape[1] \u003c 6:\n","    x_train = torch.cat([x_train] * (6 // x_train.shape[1] + 1), dim=1)  # Repeat columns\n","    x_train = x_train[:, :6]  # Trim to 6 features\n","\n","# Apply PCA only if x_train has more than 6 features\n","n_components = min(6, x_train.shape[1])  # Adjust dynamically\n","pca = PCA(n_components=n_components)\n","\n","# Convert tensor to numpy and apply PCA\n","x_train_reduced = pca.fit_transform(x_train.numpy())\n","\n","# Convert back to tensor\n","x_train_reduced = torch.tensor(x_train_reduced, dtype=torch.float32)\n","\n","# Print new shape\n","print(\"New shape of x_train after PCA:\", x_train_reduced.shape)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1742891083940,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"X_UQU61OuuLu","outputId":"ad60b1a2-6762-4ef2-c4b5-63bcd2958e01"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-12-1bc2c5edc74e\u003e:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x_train_tensor = torch.tensor(x_train_reduced, dtype=torch.float32)\n","\u003cipython-input-12-1bc2c5edc74e\u003e:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Ensure correct shape\n"]}],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Convert x_train_reduced to tensor (if not already)\n","x_train_tensor = torch.tensor(x_train_reduced, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # Ensure correct shape\n","\n","# Define the model\n","class QuantumGNN(nn.Module):\n","    def __init__(self, input_dim=6, hidden_dim=32, output_dim=1):\n","        super(QuantumGNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","# Initialize model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = QuantumGNN().to(device)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4614,"status":"ok","timestamp":1742891094443,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"HumSY3fIuwUt","outputId":"d14fa252-7014-4b66-91cb-f3e060c8b831"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10 - Loss: 0.5080\n","Epoch 2/10 - Loss: 0.3590\n","Epoch 3/10 - Loss: 0.2738\n","Epoch 4/10 - Loss: 0.2446\n","Epoch 5/10 - Loss: 0.2522\n","Epoch 6/10 - Loss: 0.2696\n","Epoch 7/10 - Loss: 0.2776\n","Epoch 8/10 - Loss: 0.2715\n","Epoch 9/10 - Loss: 0.2558\n","Epoch 10/10 - Loss: 0.2374\n","Model trained successfully! ✅\n"]}],"source":["# Define loss function and optimizer\n","loss_fn = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    pred = model(x_train_tensor.to(device))\n","    loss = loss_fn(pred, y_train_tensor.to(device))\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n","\n","print(\"Model trained successfully! ✅\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1742891098145,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"P4xzm84Qu3tP","outputId":"4bc52f2b-ad94-4ddd-df5b-f9ced42a3790"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Prediction: 0.1908\n"]}],"source":["# Create test sample with 6 features\n","x_sample = torch.rand(1, 6).to(device)\n","\n","# Make prediction\n","with torch.no_grad():\n","    output = model(x_sample)\n","    print(f\"Test Prediction: {output.item():.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7jNF1kXvmOn"},"outputs":[],"source":["!pip install pennylane\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1742891115650,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"jxDBlKS91yyd"},"outputs":[],"source":["import pennylane as qml\n","\n","# Define quantum device with 6 qubits\n","n_qubits = 6\n","dev = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","@qml.qnode(dev, interface=\"torch\")\n","def quantum_layer(inputs, weights):\n","    \"\"\"Quantum Layer with Parameterized Rotation Gates\"\"\"\n","    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))  # Encode input data\n","    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum operations\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]  # Measure\n","\n","# Initialize quantum weights randomly\n","n_layers = 3  # Number of entanglement layers\n","quantum_weights = torch.randn((n_layers, n_qubits, 3), requires_grad=True)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1742891120041,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"EETQKSvC10d0"},"outputs":[],"source":["class HybridQuantumGNN(nn.Module):\n","    def __init__(self, input_dim=6, hidden_dim=32, output_dim=1):\n","        super(HybridQuantumGNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)  # Classical processing\n","        self.fc2 = nn.Linear(hidden_dim + n_qubits, output_dim)  # Merge with Quantum output\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Pass through classical layers\n","        quantum_out = torch.tensor(quantum_layer(x, quantum_weights), dtype=torch.float32)  # Quantum layer\n","        x = torch.cat((x, quantum_out), dim=-1)  # Merge classical and quantum outputs\n","        return self.fc2(x)\n","\n","# Initialize Hybrid Model\n","model = HybridQuantumGNN().to(device)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1742891412842,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"tBTk615LbF2b"},"outputs":[],"source":["@qml.qnode(dev, interface=\"torch\")\n","def quantum_layer(inputs, weights):\n","    \"\"\"Quantum Layer with Parameterized Rotation Gates\"\"\"\n","    qml.templates.AngleEmbedding(inputs[0], wires=range(n_qubits))  # Fix: Use first sample\n","    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum operation\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]  # Measurement\n","\n","# Ensure input is correctly formatted\n","inputs = x_train_tensor  # Assign inputs\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62,"status":"ok","timestamp":1742891415435,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"Bc_99_D7a03Z","outputId":"e080a1c0-1831-4c1d-d26f-7ab8bbf73ff8"},"outputs":[{"data":{"text/plain":["AngleEmbedding(tensor([[-2.0725,  2.0319,  1.8808,  1.0369,  1.0147,  0.3700],\n","        [-1.3074, -0.4552,  0.0246,  1.1329,  0.4173, -3.1521],\n","        [-3.1748, -1.2226, -0.0435,  2.1426, -3.1997, -1.5298],\n","        [ 1.4889, -0.0507,  0.9985,  0.6482, -1.9622,  1.8714],\n","        [-1.0359,  2.4182,  1.3418, -0.2809,  1.2391, -0.5326],\n","        [-1.0413, -0.0829,  2.2624, -3.3152, -3.2647, -0.6671],\n","        [ 1.0532,  1.3748, -3.1921, -0.6039,  0.8925, -1.8472],\n","        [ 1.2437, -1.2429, -2.0474,  4.1253,  1.2953, -0.5584],\n","        [-0.3032, -2.4142,  0.8092, -0.4059,  1.5905,  1.1689],\n","        [ 1.6649,  2.1830, -1.4340,  1.6473, -1.9295,  0.8671],\n","        [ 2.2663, -0.9844, -2.3617,  0.3858, -2.6875, -1.3617],\n","        [-1.6703,  0.4509,  1.5536, -1.5292, -1.7719, -0.2432],\n","        [ 0.5822, -1.6667,  0.5841, -0.0135, -0.7343, -2.9472],\n","        [ 0.1987,  0.7951,  0.2174, -0.6362, -1.8020, -0.1649],\n","        [-1.3062,  1.6482, -1.4477, -0.5355, -1.7694,  2.5192],\n","        [ 0.1039,  1.3207, -1.3461, -1.2605,  1.4910,  0.4262],\n","        [ 0.9053, -1.4669,  0.4460, -2.2864, -0.2916, -0.2272],\n","        [-0.7722, -2.4263, -1.1815,  0.5068,  0.8155,  3.1317],\n","        [-0.8982,  1.2811, -0.7431, -1.4015,  0.4995, -0.4390],\n","        [-0.3188,  0.0722, -3.0072, -1.1822,  0.2371,  0.4059],\n","        [ 0.3411, -1.1183, -0.3789, -0.5549, -0.5124,  0.4874],\n","        [-2.6140,  1.1457, -1.5204,  0.5876, -1.0052,  1.7281],\n","        [-0.1659,  1.4562, -1.0898, -1.1357, -3.3846, -0.9930],\n","        [-1.3971, -0.1508, -1.0522, -0.4367, -0.5876, -1.3187],\n","        [-0.7377, -0.5783,  1.3331, -0.9402, -0.9267,  1.2378],\n","        [ 2.0097,  1.2368,  0.5270, -0.5352,  2.0084, -0.8575],\n","        [ 2.8517, -0.6165,  0.5757,  1.3713,  0.5792, -0.5966],\n","        [ 0.0534,  1.1263,  0.0859,  0.0670,  0.4441, -1.6645],\n","        [-0.4847,  0.4288, -0.2327, -0.9445, -0.6414, -1.0907],\n","        [ 2.2239, -0.8697, -0.1849, -0.1755,  0.8520,  1.1133],\n","        [-0.7204,  0.1759,  0.7205,  4.3898, -1.8831,  1.2095],\n","        [ 1.1766, -1.8008,  0.5137, -2.7046, -1.1758, -0.1402],\n","        [-2.2567, -0.7424,  0.6514,  0.1430,  0.0189, -0.0202],\n","        [-0.8039,  2.1499,  2.0951,  0.1761,  0.3119,  0.1648],\n","        [-0.4492, -0.5924,  2.3667,  1.6409, -1.1549,  0.3025],\n","        [ 0.3505, -0.5889, -0.9030, -0.6584, -0.3690, -0.1356],\n","        [-0.4740, -4.3299, -0.4192,  0.3205,  1.4658, -1.2237],\n","        [-0.3741, -0.6087,  0.0930,  0.1007, -0.1643,  2.5883],\n","        [-0.3650,  0.1834,  0.1853,  0.9614,  0.4116,  1.2384],\n","        [-1.0815, -1.1838, -0.1760,  2.4484,  0.1232,  0.7160],\n","        [ 2.1911,  2.2196, -1.1168,  1.1945,  0.6917, -1.2582],\n","        [ 0.6967,  1.2264,  0.2828,  1.1787,  0.0879, -2.9494],\n","        [ 0.2095, -1.2615,  0.7504, -0.5621,  0.9161,  0.1021],\n","        [ 2.3223, -1.3092, -0.1601,  0.8940,  0.7818, -0.9264],\n","        [ 0.5278,  0.8656,  2.4572, -1.4098,  2.3733, -0.9340],\n","        [-0.4682,  0.9510,  2.9528,  0.2364,  0.8437,  0.0200],\n","        [ 0.2834, -2.0061,  1.8130,  1.4972,  1.7530,  0.2810],\n","        [ 0.7090, -3.4181, -0.3646,  0.9622, -1.1194,  0.2325],\n","        [ 2.4480,  0.2032, -0.8813, -0.8441, -0.3401,  0.4037],\n","        [-0.1723, -1.1490,  0.2016,  0.9202,  1.3019,  1.4464],\n","        [ 4.8233,  0.1616,  2.5733, -1.0796,  2.1276,  0.7736],\n","        [ 1.8770,  3.8723, -1.2186, -1.3458, -1.1030,  1.1207],\n","        [ 0.4951,  0.5793,  0.1629,  1.9199, -0.5560, -1.9136],\n","        [-0.0904, -0.2155,  2.8239, -0.4582,  2.1108, -1.5180],\n","        [-1.4408, -1.5081,  0.7500,  0.0766, -0.3206,  1.9705],\n","        [-1.9314, -0.4422, -0.5676, -1.2759,  0.3717,  0.8510],\n","        [-2.9381,  0.6970, -1.5193, -0.7680, -0.3305, -1.7891],\n","        [ 2.1755,  0.3129, -2.2801,  0.8805,  0.0885, -0.3414],\n","        [ 1.4384, -0.6759,  1.7636,  1.7959, -1.2514,  0.8682],\n","        [-1.0437, -0.9637, -0.7407, -0.6734,  1.4087, -1.1156],\n","        [ 1.0559, -2.9985, -0.5735,  0.6167, -2.2215,  0.4522],\n","        [-1.9302,  0.0790, -1.1266, -0.2090,  0.7172, -0.8890],\n","        [-1.1126, -0.1073, -0.2296,  0.7324, -1.0046,  0.6087],\n","        [ 0.3308,  1.1745, -2.1711, -0.4861,  2.8662, -1.0238],\n","        [ 2.4155, -2.5318,  0.1652,  0.4334,  1.2190,  1.0328],\n","        [ 1.3062,  2.1372,  0.1429,  0.5821,  0.5185, -1.3078],\n","        [ 1.5450,  0.5303, -0.3357, -2.1052, -1.1219,  0.5698],\n","        [ 0.1369,  1.4611, -0.2355, -1.3909,  1.2947,  1.7927],\n","        [ 0.4243, -1.5444, -1.2452, -1.5763,  0.1134,  2.7323],\n","        [-0.1958,  3.5204,  0.5619,  2.3257,  0.2067,  0.8433],\n","        [-1.5706,  1.1562,  1.6035,  1.2497,  0.6233, -1.2485],\n","        [ 2.2194,  1.3946,  0.9775,  0.9071,  1.0181,  0.9985],\n","        [-0.3356,  0.9115,  1.8160,  0.2463, -1.3842, -0.4703],\n","        [ 1.1721, -0.3402, -1.3016,  0.0312,  0.5942,  0.2658],\n","        [-1.1986, -1.4660,  0.0275, -2.1964,  0.5072, -2.8464],\n","        [ 0.2068,  0.8717, -1.6743,  1.0622,  1.2125, -1.0302],\n","        [ 3.5202,  0.7521,  2.7975, -0.6307, -2.9211,  0.8392],\n","        [-1.9719,  1.0189,  2.5534,  0.9780,  0.7375, -1.9036],\n","        [ 0.2755, -0.1052,  1.2795,  0.2987,  0.5432,  1.3677],\n","        [-1.5961, -0.6762, -2.8689,  0.4293,  0.2159,  0.4821],\n","        [ 0.6378, -2.5344, -2.2672, -0.9089,  1.1483, -1.5097],\n","        [ 1.2304, -0.5661, -0.7426,  0.5210, -1.3278, -0.7227],\n","        [ 0.6460,  0.6342, -0.7189, -0.7245,  0.7947,  1.2290],\n","        [-0.4338,  1.0300,  0.8522, -0.8063,  1.3268,  1.9782],\n","        [-3.8157, -0.3381,  0.3896, -4.0529,  1.2959,  0.9544],\n","        [-3.1989, -0.7714,  1.7862,  1.3826,  1.3575, -0.3172],\n","        [ 0.4108, -0.4356,  0.7180, -2.3170,  0.2465,  0.2536],\n","        [ 1.4115,  0.1460,  1.0815,  0.2188,  0.2863, -1.3827],\n","        [-2.8617,  0.8597,  0.2452,  1.6308, -1.6668,  0.7536],\n","        [-0.7469,  0.1884, -0.3518, -0.3804,  0.3863,  0.3561],\n","        [ 1.3202,  3.1358, -1.2138, -0.9275, -0.8436,  0.1212],\n","        [-0.3857,  0.1770, -0.7734,  0.3080, -0.4671,  0.4797],\n","        [-0.9750, -0.4707, -2.1300,  0.1352,  0.0560, -1.0762],\n","        [ 0.5744,  1.3565, -0.7974, -0.9484, -1.2430, -0.7027],\n","        [-0.6017, -1.8177, -0.7483,  0.6790,  0.7027,  0.6999],\n","        [ 1.3848, -2.7213,  2.3256, -1.5143, -2.9582, -1.8671],\n","        [ 0.0127,  1.6477,  0.3478,  1.2428,  0.7246,  1.3812],\n","        [-0.7773, -0.0127,  0.3199, -0.5498,  1.8475,  1.3228],\n","        [-2.2811,  0.8655, -1.2146, -0.0945,  0.0761, -0.5580],\n","        [-1.0487, -0.0363, -1.4582,  0.3731,  0.1974,  2.1814]]), wires=[0, 1, 2, 3, 4, 5], rotation=X)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1742891421722,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"c9MkDVBaaWRp"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components=n_qubits)  # Reduce to 6 features\n","x_train_reduced = pca.fit_transform(x_train.numpy())  # Convert tensor to NumPy for PCA\n","x_train_tensor = torch.tensor(x_train_reduced, dtype=torch.float32).to(device)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1742891538876,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"cAQeY-nibkqj"},"outputs":[],"source":["x_train_tensor = x_train_tensor[:, :n_qubits]  # Keep only first 6 features\n"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1742892366953,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"AdNgK-vQbuZ3"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components=n_qubits)  # Reduce features to match quantum wires\n","x_train_reduced = pca.fit_transform(x_train_tensor.cpu().numpy())\n","x_train_tensor = torch.tensor(x_train_reduced, dtype=torch.float32).to(device)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":5500,"status":"ok","timestamp":1742892822295,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"TsvPFSrJgZqV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pennylane as qml\n","\n","# Number of qubits (6 in this case)\n","n_qubits = 6\n","\n","# Define Quantum Layer\n","dev = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","@qml.qnode(dev, interface=\"torch\")\n","def quantum_layer(inputs, weights):\n","    \"\"\"Quantum Layer with Parameterized Rotation Gates\"\"\"\n","    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))  # Encode input data\n","    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum operations\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]  # Measurement\n","\n","# Neural Network with Classical + Quantum layers\n","class HybridQuantumModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(HybridQuantumModel, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, n_qubits)  # Reduce 32 → 6 features\n","        self.fc2 = nn.Linear(n_qubits + n_qubits, output_dim)  # Merge quantum \u0026 classical output\n","        self.quantum_weights = nn.Parameter(torch.randn((n_qubits, 3)))  # Quantum weights\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Classical dimension reduction\n","        quantum_out = torch.tensor(quantum_layer(x, self.quantum_weights), dtype=torch.float32)  # Quantum layer\n","        x = torch.cat((x, quantum_out), dim=-1)  # Merge classical and quantum output\n","        return self.fc2(x)\n","\n","# Define model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = HybridQuantumModel(input_dim=32, output_dim=1).to(device)\n"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1742892925725,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"UZLAu_s9gzyV"},"outputs":[],"source":["# Define Loss Function and Optimizer\n","loss_fn = nn.MSELoss()  # Mean Squared Error for regression\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1742893826575,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"CcdRhyzRkS55"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class GNNQuantumModel(nn.Module):\n","    def __init__(self):\n","        super(GNNQuantumModel, self).__init__()\n","        self.fc1 = nn.Linear(6, 32)  # Accepts 6 input features, outputs 32\n","        self.fc2 = nn.Linear(32, 1)  # Final output layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Pass through classical layers\n","        return self.fc2(x)  # Output\n","\n","# Initialize the model\n","model = GNNQuantumModel()\n"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1742893853722,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"lE1-WInSkZDl"},"outputs":[],"source":["pred = model(x_train_tensor.to(device))\n"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1742893965457,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"7BvW3MtNk0wk","outputId":"54730ee3-67c3-4db9-9cf2-7bb28e70dccc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Output Shape: torch.Size([10, 1])\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Define the GNN Quantum Model\n","class GNNQuantumModel(nn.Module):\n","    def __init__(self):\n","        super(GNNQuantumModel, self).__init__()\n","        self.fc1 = nn.Linear(6, 32)  # Accepts 6 input features, outputs 32\n","        self.fc2 = nn.Linear(32, 1)  # Final output layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))  # Pass through classical layers\n","        return self.fc2(x)  # Output layer\n","\n","# ✅ Initialize the model properly\n","model = GNNQuantumModel()\n","\n","# ✅ Use the model correctly\n","x_train_tensor = torch.randn(10, 6)  # Simulating input data (10 samples, 6 features)\n","output = model(x_train_tensor)\n","print(\"Model Output Shape:\", output.shape)  # Expected: (10, 1)\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1742894184670,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"YeMtSjkQlqVf","outputId":"abd65a5d-23dd-4875-e7e0-006b7bb81d7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Loss: 1.2086\n","Epoch 2/10, Loss: 1.0934\n","Epoch 3/10, Loss: 0.9974\n","Epoch 4/10, Loss: 0.9193\n","Epoch 5/10, Loss: 0.8529\n","Epoch 6/10, Loss: 0.7950\n","Epoch 7/10, Loss: 0.7422\n","Epoch 8/10, Loss: 0.6911\n","Epoch 9/10, Loss: 0.6448\n","Epoch 10/10, Loss: 0.5979\n"]}],"source":["# Set up optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","loss_fn = nn.MSELoss()  # Mean Squared Error for regression tasks\n","\n","# Example target values (y_train)\n","y_train_tensor = torch.randn(10, 1)  # Simulated target data\n","\n","# Train the model for 10 epochs\n","epochs = 10\n","for epoch in range(epochs):\n","    optimizer.zero_grad()  # Reset gradients\n","    pred = model(x_train_tensor)  # Forward pass\n","    loss = loss_fn(pred, y_train_tensor)  # Compute loss\n","    loss.backward()  # Backpropagation\n","    optimizer.step()  # Update weights\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64556,"status":"ok","timestamp":1742894272577,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"kZ34h-B5lwb0","outputId":"8506c612-66c7-433c-9c79-7fb12f4eb51f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Predictions: tensor([[-0.9496],\n","        [-0.1218],\n","        [-0.6662],\n","        [ 0.0160],\n","        [ 0.0578]])\n"]}],"source":["# Generate new test data\n","x_test_tensor = torch.randn(5, 6)  # Simulated test data (5 samples, 6 features)\n","\n","# Predict with the trained model\n","with torch.no_grad():\n","    y_pred = model(x_test_tensor)\n","\n","print(\"Test Predictions:\", y_pred)\n"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1742894505649,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"xPKrnTzCm34G"},"outputs":[],"source":["def quantum_layer(inputs, weights):\n","    \"\"\"Quantum Layer with Parameterized Rotation Gates\"\"\"\n","    print(f\"🚀 Running Quantum Layer with inputs: {inputs.shape}\")  # Debugging step\n","    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))  # Encode classical data\n","    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum operation\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]  # Measurement\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113,"status":"ok","timestamp":1742894607848,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"9WjNV5KFm6yy","outputId":"6cfc17df-3888-4f64-9ad2-407467f6417b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0: Loss = 0.5495\n","Epoch 10: Loss = 0.1202\n","Epoch 20: Loss = 0.0339\n","Epoch 30: Loss = 0.0030\n","Epoch 40: Loss = 0.0027\n","✅ Model retrained and saved successfully!\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define loss and optimizer\n","loss_fn = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","epochs = 50  # Adjust based on performance\n","\n","for epoch in range(epochs):\n","    optimizer.zero_grad()  # Reset gradients\n","    pred = model(x_train_tensor.to(device))  # Forward pass\n","    loss = loss_fn(pred, y_train_tensor.to(device))  # Compute loss\n","    loss.backward()  # Backpropagation\n","    optimizer.step()  # Update weights\n","\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n","\n","# Save the trained model\n","torch.save(model.state_dict(), \"gnn_model.pth\")\n","print(\"✅ Model retrained and saved successfully!\")\n"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1742894672878,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"jhLrLBrq2BI_","outputId":"08611ff7-3eeb-48d4-d26c-f42305fdfcc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10 - Loss: 0.0003\n","Epoch 2/10 - Loss: 0.0133\n","Epoch 3/10 - Loss: 0.0054\n","Epoch 4/10 - Loss: 0.0083\n","Epoch 5/10 - Loss: 0.0037\n","Epoch 6/10 - Loss: 0.0034\n","Epoch 7/10 - Loss: 0.0051\n","Epoch 8/10 - Loss: 0.0035\n","Epoch 9/10 - Loss: 0.0012\n","Epoch 10/10 - Loss: 0.0016\n","Quantum Model trained successfully! ✅\n"]}],"source":["# Define loss function and optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    pred = model(x_train_tensor.to(device))\n","    loss = loss_fn(pred, y_train_tensor.to(device))\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n","\n","print(\"Quantum Model trained successfully! ✅\")\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1742894724731,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"tKS7p9l8nukE","outputId":"ea5e78e7-9d33-479d-e275-96c2b53c3842"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 3.1K Mar 25 09:23 gnn_model.pth\n"]}],"source":["!ls -lh gnn_model.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqs76K6L1cZ_"},"outputs":[],"source":["!pip install fastapi uvicorn torch ngrok rdkit-pypi torch-geometric\n"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8301,"status":"ok","timestamp":1742894821962,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"jN6YCWwN2pvu","outputId":"c8668136-b158-4581-fb6f-9dec3f150a23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}],"source":["!pip install pyngrok\n","!ngrok authtoken 2kc4JYfGdClgGVNKzItDWCdqWUu_6zLureLG3Vs4L2jcvhV9Z\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9zHrYpqy3Qj-"},"outputs":[{"name":"stdout","output_type":"stream","text":["🚀 Public URL: https://6d46-34-73-238-66.ngrok-free.app\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [41401]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     2401:4900:2642:7b11:8590:de45:646c:dbad:0 - \"GET / HTTP/1.1\" 200 OK\n","INFO:     2401:4900:2642:7b11:8590:de45:646c:dbad:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n"]}],"source":["import nest_asyncio\n","import uvicorn\n","from fastapi import FastAPI\n","from pyngrok import ngrok\n","\n","# ✅ Fix: Allow uvicorn to run inside a notebook\n","nest_asyncio.apply()\n","\n","app = FastAPI()\n","\n","@app.get(\"/\")\n","def home():\n","    return {\"message\": \"FastAPI is running on Google Colab\"}\n","\n","# ✅ Start Ngrok tunnel\n","public_url = ngrok.connect(7860).public_url\n","print(f\"🚀 Public URL: {public_url}\")\n","\n","# ✅ Run Uvicorn inside the notebook\n","uvicorn.run(app, host=\"0.0.0.0\", port=7860)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1742490151257,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"7_hOtNDtgXc4","outputId":"5a08a74e-d2fd-40e8-8570-20acb72fb290"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Token set successfully!\n"]}],"source":["import os\n","\n","# Set Hugging Face Token as an environment variable\n","os.environ[\"HUGGINGFACE_TOKEN\"] = \"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\"\n","\n","print(\"✅ Token set successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ja1NllcFgbJV"},"outputs":[],"source":["from huggingface_hub import login\n","\n","# Use your token securely\n","login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3088,"status":"ok","timestamp":1742490416172,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"jMaji_YhhXg0","outputId":"8f4d97fb-c911-4676-834b-9ee1c16feeda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.1\n"]}],"source":["!pip install python-dotenv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1742490436927,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"KctPUg4Lhc3v","outputId":"ad7a7d68-bf13-4aca-912e-19361eb9db46"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Token loaded securely!\n"]}],"source":["from dotenv import load_dotenv\n","import os\n","\n","# Specify the path to the .env file\n","dotenv_path = \"/content/.env.txt\"\n","\n","# Load the .env file\n","load_dotenv(dotenv_path)\n","\n","# Retrieve the Hugging Face Token\n","huggingface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n","\n","# Check if token is loaded\n","if huggingface_token:\n","    print(\"✅ Token loaded securely!\")\n","else:\n","    print(\"❌ Token not found. Check the file path.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1742490453975,"user":{"displayName":"Rebeca suji A","userId":"16023161171056050128"},"user_tz":-330},"id":"Jee5dcmShjhv","outputId":"89b77dcc-623c-487c-adff-78e37582fbfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Successfully authenticated with Hugging Face!\n"]}],"source":["from huggingface_hub import login\n","\n","login(token=huggingface_token)  # Authenticate with Hugging Face\n","\n","print(\"✅ Successfully authenticated with Hugging Face!\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM7bw+a4MweORdEC6CCwtcV","name":"","provenance":[{"file_id":"11gDyNAM_bJBdSY5Tzt-3CoEp_66EG7zR","timestamp":1742495243680}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d4fc53a8a44f78950370e9ab45c152":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06c7c31657fc469b8ad90194c2698ca0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7006cb7a999944269dcba45090c0d8d3","IPY_MODEL_8006380be36c49d1bedd9335e27a8828","IPY_MODEL_63f508396bf2444180a28b191c09a9ba"],"layout":"IPY_MODEL_e8e5917b0e6f49919c7ba7d23f6fc9ec"}},"0f98e7519ef740bc9de2df1dfd96273d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18bfce83ad3b46cfb8c1d3346b93fdfe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2634a08906504d869f805682919e931a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f5cb40749a04312bccae7c0f8737c5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"494c8dfa8cef4fb79efbe6fe1cacd184":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f803b11bb1c453cac1050f386b5530b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0ae3f4fa96748e98e195d42dd711d1e","placeholder":"​","style":"IPY_MODEL_00d4fc53a8a44f78950370e9ab45c152","value":" 69.3M/69.3M [00:00\u0026lt;00:00, 132MB/s]"}},"5325fd60dafb4cf7a5ac7e845054e123":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5392ffb68bf249a7b6866727c49d8968":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db8977866d549c594f1cacd477f4a30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63f508396bf2444180a28b191c09a9ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18bfce83ad3b46cfb8c1d3346b93fdfe","placeholder":"​","style":"IPY_MODEL_2f5cb40749a04312bccae7c0f8737c5b","value":" 802/802 [00:00\u0026lt;00:00, 14.5kB/s]"}},"7006cb7a999944269dcba45090c0d8d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_723f7d275aad4d84a20d7d7a29b55199","placeholder":"​","style":"IPY_MODEL_915e5722148a45e78bd2f41cc06f8bbb","value":"README.md: 100%"}},"723f7d275aad4d84a20d7d7a29b55199":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7729d9fd7cb3462c98c27f555bc0b22f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce29c05715844ac4aa110309f77bdc28","IPY_MODEL_e47e692ab4644eddaf8d790af182a332","IPY_MODEL_4f803b11bb1c453cac1050f386b5530b"],"layout":"IPY_MODEL_cca351ad8c504f23b0819b5f8339b03f"}},"7e35707dbb9b4e4bb7f8b08435edc235":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8006380be36c49d1bedd9335e27a8828":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a58b657115405eab4753c94ba6e7a5","max":802,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f98e7519ef740bc9de2df1dfd96273d","value":802}},"915e5722148a45e78bd2f41cc06f8bbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9604ca0647574b5a956da2b77b3181b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9897f9e1fa844bd69625da95daed0db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98a58b657115405eab4753c94ba6e7a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac298f7b544a4217905ca314b670d584":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae9538fbff5d4c00b6d964ec44d3a13b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2f609e7f48c47308acaee5155d1162d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5392ffb68bf249a7b6866727c49d8968","placeholder":"​","style":"IPY_MODEL_7e35707dbb9b4e4bb7f8b08435edc235","value":" 249455/249455 [00:01\u0026lt;00:00, 189780.38 examples/s]"}},"b3379b551d97481aa8f53a7f53b1cbce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cab8606fe7ad47dab46d4a00a8e6d72a","IPY_MODEL_c6c19e59e9c4430a88716b836c918149","IPY_MODEL_b2f609e7f48c47308acaee5155d1162d"],"layout":"IPY_MODEL_9604ca0647574b5a956da2b77b3181b1"}},"c6c19e59e9c4430a88716b836c918149":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5325fd60dafb4cf7a5ac7e845054e123","max":249455,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae9538fbff5d4c00b6d964ec44d3a13b","value":249455}},"cab8606fe7ad47dab46d4a00a8e6d72a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5db8977866d549c594f1cacd477f4a30","placeholder":"​","style":"IPY_MODEL_9897f9e1fa844bd69625da95daed0db3","value":"Generating train split: 100%"}},"cca351ad8c504f23b0819b5f8339b03f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce29c05715844ac4aa110309f77bdc28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_494c8dfa8cef4fb79efbe6fe1cacd184","placeholder":"​","style":"IPY_MODEL_2634a08906504d869f805682919e931a","value":"zinc250k_selfies.csv: 100%"}},"cf6faa9f848342458434e088254b878a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0ae3f4fa96748e98e195d42dd711d1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47e692ab4644eddaf8d790af182a332":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf6faa9f848342458434e088254b878a","max":69323598,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac298f7b544a4217905ca314b670d584","value":69323598}},"e8e5917b0e6f49919c7ba7d23f6fc9ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}